{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction Exercise in Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use NLTK for entity extraction. \n",
    "- Firstly, install python environment\n",
    "- Change the source mirror of pip : https://mirrors.bfsu.edu.cn/help/pypi/\n",
    "- Install NLTK: pip install nltk\n",
    "- Download data distribution for NLTK. Enter python terminal first. import nltk. Install packages by using NLTK downloader: ``nltk.download()``. If cannot download using ``nltk.download()``, try download manually from https://github.com/nltk/nltk_data/tree/gh-pages![image.png](attachment:image.png) or https://pan.baidu.com/s/1wONWpaa86_wnsIksKda8eQ (code:tfon )\n",
    "- Unzip the downloaded file to the following folder: ``nltk.data.find(\".\")``\n",
    "- Unzip each zip file in the ten folders: *chunkers, corpora, grammers, help, misc, models, sentiment, stemmers, taggers, tokenizers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading tagset: [WinError 10060]\n",
      "[nltk_data]     由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"tagsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John was born in Liverpool, to Julia and Alfred Lennon']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize sentence:\n",
    "raw = \"\"\"John was born in Liverpool, to Julia and Alfred Lennon\"\"\"\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "tokens = tokenizer.tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John was born in Liverpool, to Julia and Alfred Lennon', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# pos-tag of inputs\n",
    "#output: a list of tokens with pos tags\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know the detail information of each tag, use the following statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "#You can call the following method to get info about any pos tag\n",
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking:\n",
    "- Use ``ne_chunk`` provided by NLTK. ``ne_chunk`` needs part-of-speech annotations to add ``NE`` labels to the sentence. The output of the ``ne_chunk`` is a ``nltk.Tree`` object\n",
    "- ``ne_chunk`` produces 2-level trees:\n",
    " - Nodes on Level-1: outsides any chunk\n",
    " - Nodes on Level-2: inside a chunk (the label of the chunk is denoted by the label of the subtree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON John/NNP)\n",
      "  was/VBD\n",
      "  born/VBN\n",
      "  in/IN\n",
      "  (GPE Liverpool/NNP)\n",
      "  ,/,\n",
      "  to/TO\n",
      "  (GPE Julia/NNP)\n",
      "  and/CC\n",
      "  (PERSON Alfred/NNP Lennon/NNP))\n"
     ]
    }
   ],
   "source": [
    "#import related packages\n",
    "from nltk import pos_tag, ne_chunk\n",
    "text = \"\"\"John was born in Liverpool, to Julia and Alfred Lennon\"\"\"\n",
    "chunks = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "print(chunks)\n",
    "chunks.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tree.Tree"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON John/NNP) <class 'nltk.tree.Tree'>\n",
      "('was', 'VBD') <class 'tuple'>\n",
      "('born', 'VBN') <class 'tuple'>\n",
      "('in', 'IN') <class 'tuple'>\n",
      "(GPE Liverpool/NNP) <class 'nltk.tree.Tree'>\n",
      "(',', ',') <class 'tuple'>\n",
      "('to', 'TO') <class 'tuple'>\n",
      "(GPE Julia/NNP) <class 'nltk.tree.Tree'>\n",
      "('and', 'CC') <class 'tuple'>\n",
      "(PERSON Alfred/NNP Lennon/NNP) <class 'nltk.tree.Tree'>\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    print(i, type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON\n",
      "John NNP\n",
      "GPE\n",
      "Liverpool NNP\n",
      "GPE\n",
      "Julia NNP\n",
      "PERSON\n",
      "Alfred NNP\n",
      "Lennon NNP\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    if type(i) == Tree:\n",
    "        print(i.label())\n",
    "        chunk_phrase = []\n",
    "        for token, pos in i.leaves():\n",
    "            print(token, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Julia is labled as GPE instead of PERSON\n",
    "add a lastname for Julia, such as Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON John/NNP)\n",
      "  was/VBD\n",
      "  born/VBN\n",
      "  in/IN\n",
      "  (GPE Liverpool/NNP)\n",
      "  ,/,\n",
      "  to/TO\n",
      "  (PERSON Julia/NNP Kim/NNP)\n",
      "  and/CC\n",
      "  (PERSON Alfred/NNP Lennon/NNP))\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"John was born in Liverpool, to Julia Kim and Alfred Lennon\"\"\"\n",
    "chunks = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "print(chunks)\n",
    "chunks.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traverse the chunked tree structure to get each chunk and words inside each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON John/NNP) <class 'nltk.tree.Tree'>\n",
      "('was', 'VBD') <class 'tuple'>\n",
      "('born', 'VBN') <class 'tuple'>\n",
      "('in', 'IN') <class 'tuple'>\n",
      "(GPE Liverpool/NNP) <class 'nltk.tree.Tree'>\n",
      "(',', ',') <class 'tuple'>\n",
      "('to', 'TO') <class 'tuple'>\n",
      "(PERSON Julia/NNP Kim/NNP) <class 'nltk.tree.Tree'>\n",
      "('and', 'CC') <class 'tuple'>\n",
      "(PERSON Alfred/NNP Lennon/NNP) <class 'nltk.tree.Tree'>\n"
     ]
    }
   ],
   "source": [
    "#Traverse the level-1 nodes in the tree: \n",
    "for i in chunks:\n",
    "    print(i, type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('John', 'NNP') <class 'nltk.tree.Tree'>\n",
      "was <class 'tuple'>\n",
      "born <class 'tuple'>\n",
      "in <class 'tuple'>\n",
      "('Liverpool', 'NNP') <class 'nltk.tree.Tree'>\n",
      ", <class 'tuple'>\n",
      "to <class 'tuple'>\n",
      "('Julia', 'NNP') <class 'nltk.tree.Tree'>\n",
      "and <class 'tuple'>\n",
      "('Alfred', 'NNP') <class 'nltk.tree.Tree'>\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    print(, type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk detected!\n",
      "John NNP\n",
      "Chunk detected!\n",
      "Liverpool NNP\n",
      "Chunk detected!\n",
      "Julia NNP\n",
      "Kim NNP\n",
      "Chunk detected!\n",
      "Alfred NNP\n",
      "Lennon NNP\n"
     ]
    }
   ],
   "source": [
    "#Traverse the level-2 nodes in the sub-tree: \n",
    "for i in chunks:\n",
    "    if type(i) == Tree:\n",
    "        print(\"Chunk detected!\")\n",
    "        chunk_phrase = []\n",
    "        for token, pos in i.leaves():\n",
    "            print(token, pos)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"\"\"the little dog barked at the cat\"\"\"\n",
    "grammer = \"NP: {<JJ>*<NN.*>+}\\n {<NN.*>+}\"  \n",
    "cp = nltk.RegexpParser(grammer)\n",
    "mychunk = cp.parse(pos_tag(word_tokenize(sen)))\n",
    "mychunk.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'DT') <class 'tuple'>\n",
      "(NP little/JJ dog/NN) <class 'nltk.tree.Tree'>\n",
      "('barked', 'VBD') <class 'tuple'>\n",
      "('at', 'IN') <class 'tuple'>\n",
      "('the', 'DT') <class 'tuple'>\n",
      "(NP cat/NN) <class 'nltk.tree.Tree'>\n"
     ]
    }
   ],
   "source": [
    "#print(mychunk)\n",
    "for i in mychunk:\n",
    "    print(i, type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
